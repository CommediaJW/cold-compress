{"pred": "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney.", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "A series of linear contiguous posts.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "F-score and Kappa statistics.", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The best performing configuration of the CAS-LSTM model was used as the baseline for modifications.", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "unanswerable.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "unanswerable", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "Shallow syntax does not offer any significant improvement in sentiment classification.", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "English reviews from Amazon reviews from three datasets (Amazon, Yelp restaurant reviews from Yelp and restaurant reviews from Yelp and SemEval-2016 Challenge Task 5 datasets.", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "The proposed topic-attention model achieves a remarkable increase of 12.27% on accuracy and 14.86% on F1 score.", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They use both methods: they use transcribed text from the IEMOCAP dataset and also determine text from the audio using the Google Cloud Speech API.", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "CLUTO and Carrot2 Lingo.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
